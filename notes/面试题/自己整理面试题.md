---
typora-copy-images-to: imgs
---



- 多看优秀的场景设计文章、
- 性能优化：https://wx.zsxq.com/dweb2/index/topic_detail/214251284118481
- sql 刷题建议牛客网




观看记录

Java Guide：2023-09-07 20:07



# 场景题

> 1. 场景题：匹配系统，一个用户多次匹配，要求不能匹配重复的人，之后双方都点击确认开始聊天。

   答：对于用户不可以匹配重复的人，可以使用 bitmap 来做。

> 2. 实现短信验证码生成和验证两个功能，只能使用Java语言，不能使用Redis等外部存储工具。

> 3. 如果抽奖项目真正应用于实际还有哪些地方需要改进？

答：目前架构、设计、实现上已经做了很多的优化方案，但上线肯定是会有很多的业务场景的细节，需要技术处理。为了更好的适配这些场景，在实现上留出扩展、在系统上添加监控、在日志上做好排查等。

代码的扩展性、系统的可用性


> 4. 敏感词库的设计，要求增删改查敏感词。敏感词文本匹配，敏感词一万个，文本长度在 20 - 1000 

   trie 树、开几个线程

   redis 如果宕机了怎么办？

> 5. 1亿数据只有 1gb 内存怎么去重？

> 6. 项目的登陆密码怎么存储，用的什么加密算法，为什么用 MD5？

> 7. 订单到期后，如何关闭订单？

   参考文章：https://mp.weixin.qq.com/s/BG1PqUWX0XwJX6aMCXCgvw

   - 方案一：定时任务，定时去扫描所有到期的订单，然后执行关单的动作。

     - 缺点：
       1. 时间不精确，可能订单已经到了超时时间，但是还没有到定时任务执行时间，导致订单关闭时间比超时时间晚。
       2. 无法处理大订单量，如果订单量较大，会导致定时任务执行时间很长，导致后边订单被扫描到的时间很晚。
       3. 对数据库造成压力，定时任务集中扫描表，会大量占用数据库io，可以将定时任务将其他正常业务做好隔离
       4. 分库分表问题，订单系统，在订单量大时会分库分表，在分库分表中进行全表扫描很不推荐
     - 适用场景：
       1. 对过期时间精度要求不高，业务量不大的场景

   - 方案二：JDK自带的延迟队列，`DelayQueue`，在用户创建订单时，把订单加到 `DelayQueue` 中，此外，还需要一个常驻任务不断从队列读取已经超时的订单，并进行关闭，之后再将该订单从队列中删除。

     该方案需要有一个线程添加 `while(true)` 循环，才能确保任务不断执行并及时取出超时订单。

     - 缺点：
       1. 该方案是基于 JVM 内存的，一旦机器重启，会导致数据消失，虽然可以配合数据库的持久化一起使用，但是应用一般都是集群部署，集群中的多台实例的 `DelayQueue` 如何配合也是一个很大的问题。
       2. 当订单量过大时，可能会导致 OOM 的问题。
     - 适用场景：
       1. 单机，订单量不大

   - 方案三：RockerMQ延迟消息，在订单创建好之后，发送一个延迟消息，指定延迟时间，在延迟时间到达之后，消息就会被消费者消费。

     - 缺点：
       1. RocketMQ的延迟时间不支持任意的，只支持：1s、5s、10s、30s，1m、2m等等（商业版支持任意时长）
     - 适用场景：RocketMQ支持延迟时间和我们所需延迟时间正好符合

   - 方案四：RabbitMQ插件，基于 rabbitmq_delayed_message_exchange 插件，该插件从 RabbitMQ 的 3.6.12 版本开始支持，该插件为官方开发的。

     在 RabbitMQ 中，我们设置一个消息，并且不去消费他，当过了存活时间之后，这个消息会变成死信，会被发送到死信队列中。

     在该插件中，消息并不会立即进入队列，而是先将他们保存到一个基于 Erlang 开发的 Mnesia 数据库，再通过一个定时器去查询需要被投递的消息，再投递到 x-delayed-message 队列中。

     - 适用场景：基于 RabbitMQ 插件的方式实现延迟消息，最大延长时间大概为 49 天，超过时间会被立即消费。可用性，性能都不错。

   - 方案五：Redis 过期监听，监听 key 的过期消息，在接收到过期消息之后，进行订单的关单操作。

     - 缺点：
       1. Redis 不保证 key 在过期时会被立即删除，也不保证消息能立即发出，因此存在消息延迟
       2. 在 Redis5.0 之前，这个消息是通过 PUB/SUB 模式发出的，不会进行持久化，如果发送消息时，客户端挂了，之后再恢复的话，这个消息就会彻底丢失。

   - 方案六：Redis 的 zset

     zset 是一个有序集合，每一个元素关联一个 score，通过 score 来对集合中的元素进行排序

     我们可以将（下单时间 + 超时时间） 与订单号分别设置为 score 和 元素值，通过 redis 进行排序之后，再开启 redis 扫描任务，获取 “当前时间 > score” 的任务，扫描到之后取出订单号，进行关单操作。

     - 优点：使用 redis zset 可以借助 redis 的持久化、高可用机制，避免数据丢失。在高并发场景中，可能多个消费者同时获取同一个订单号，一般采用分布式锁进行解决，也可以做幂等性（多个消费者获取同一个订单号也不影响）进行处理。

       ```bash
       # 命令示例
       # 添加两个元素 a、b 分数为 10、25
       127.0.0.1:6379> zadd delay_queue 10 a
       (integer) 1
       127.0.0.1:6379> zadd delay_queue 25 b
       (integer) 1
       # 查询分数为 9-12 的元素
       127.0.0.1:6379> zrangebyscore delay_queue 9 12 limit 0 1
       1) "a"
       ```

   - 方案七：Redission，Redission 中定义了分布式延迟队列 RDelayedQueue，即在 zset 基础上增加了一个基于内存的延迟队列，当我们添加一个元素到延迟队列时，redission 会把 数据+超时时间 放到 zset 中，并且启动一个延时任务，当任务到期时，再去 zset 中把数据取出来进行消费，允许以指定的延迟时长将元素放到目标队列中。

     - 优点：可以解决方案六中的并发问题，稳定性，性能较高

   - 方案八：RocketMQ时间轮（https://mp.weixin.qq.com/s/I91QRel-7CraP7zCRh0ISw）

   - **总体来讲，Redission + Redis、RabbitMQ插件、Redis的zset、RocketMQ延迟消息这几种方案比较推荐**



> 8. 一个系统用户登陆信息保存在服务器A上，服务器B如何获取到Session信息？（分布式 Session 共享的解决方案）

答：将 Session 数据存储到分布式缓存比如 Redis 中，所有的服务器都可以访问。

- 优点：性能优秀、支持横向扩展（Redis集群）
- 缺点：存在数据丢失风险（虽然 Redis 支持数据持久化，但仍可能丢失小部分数据）



> 9. 如果让你来评估项目的QPS的话，你会用什么方式来评估?(补充: 不要做压测，就通过现在的设计以及硬件配置推导OPS应该达到什么水准?)

答：首先需要根据业务提供的推广规模、渠道、人数，来评估。- 这里前面按照28法则评估过。

假如系统有1000万用户，那么每天来点击页面的占比20%，也就是200万用户访问。

假设平均每个用户点击50次，那么总用有1亿的PV（页面浏览量）

一天24个小时，平均活跃时间段算在5个小时内【24*20%】，那么5个小时预计有8000万点击，也就是平均每秒4500个请求。

4500是一个均值，按照电商类峰值的话，一般是3~4倍均值量，也就是5个小时每秒18000个请求【QPS=1.8万】





> 10. 比如说: 16核64G的机器，普通机械硬盘，这种情况下让你来做秒杀的系统，你会去修改和配置哪些参数?(不考虑redis、kafka等，只考虑springboot的应用)

答：如果这么个机器，一般会拆分4核16G 的4台虚拟机，之后是 JVM、Tomcat 的参数配置。与大家提到的点一致。拆分为4台虚拟机之后，相当于是互备容灾。

不存在64G内存机器的配置，在云原生时代，大家更倾向于用小机器组成阵列，去扛流量。不够就伸缩，到阿里云去买公有云，这就要求你10分钟能上架应用。（微博的XX出轨应对策略，也是这个意思，加机器抗流量）

因此在答这道题时，需要首先关注的就是配置上的缺陷，之后再去解决JVM配置调优的问题。



> 11. JVM的堆配置过大的副作用有哪些?

答：垃圾回收慢，有延迟，回收频繁，也会导致碎片化严重。同时还会因为更多的占用内存和CPU导致资源竞争。

> 12. 接上面，SpringBoot和JVM需要配置的参数还有哪些?

答：主要集中在池化和组件的使用配置上，如；线程池、连接池、RPC重试和超时等



> 13. 秒杀场景下用哪种垃圾回收器合适?

答：基本就是G1，但估计想让你解释下 G1 【分代收集、并发标记、区域回收、自适应调整】- 理由；在秒杀场景中，由于请求量大、并发高，需要尽量减少应用的停顿时间，以提高系统的响应速度和吞吐量。



> 14. Full GC卡顿时间长短跟什么有关系? 如果堆大小为128G的话，Full GC可能停顿多久?

答：堆大小、垃圾回收器，此场景快速秒杀就结束了，预计也就在百十毫秒。如果更准确这个就太依赖于环境配置的验证了。



> 15.微信二维码扫描原理：

**流程：**

![1696731916684](imgs/1696731916684.png)

总的来说，PC 端需要进行扫码登陆的原理是通过二维码绑定移动端的身份信息以及PC端的设备信息，根据这两个信息生成 token 给 PC 端，PC 端就登陆成功了。

二维码准备：

1. PC端向服务器发起请求，表示要生成用户二维码，并且把 PC 端设备信息也传递给服务端
2. 服务端收到请求后，生成唯一的二维码 ID，并将二维码 ID 与 PC 端设备信息进行绑定
3. 服务端将二维码 ID 返回给 PC 端
4. PC 端收到二维码 ID 后，生成二维码
5. PC 端为了及时知道二维码的状态（是否已经扫描，扫描后是否已经确认），会不断轮询服务端，请求服务端当前二维码的状态及相关信息

扫描状态切换：

1. 用户扫描二维码后，读取到二维码 ID
2. 向服务端发送请求，并携带移动端的身份信息与二维码 ID
3. 服务端接收之后将身份信息与二维码 ID 进行绑定，生成临时 token，返回给移动端
4. 在移动端扫描完之后，PC 端会轮询二维码状态，修改为已扫描，此时二维码 ID 会与账号信息进行绑定

第三步返回给移动端临时 token 是要保证移动端在下一步操作时，使用这个临时 tokne 作为凭证，保证两步操作是同一部设备发出的，临时 token 只可以使用一次就失效。

登陆确认：

1. 移动端接收到临时 token 后会弹出确认登陆界面，点击确认，移动端会携带临时 token 调用服务端接口
2. 服务端收到确认后，根据二维码 ID 绑定的设备信息与账号信息，生成 PC 端 token
3. PC 端轮询二维码状态，修改为已确认
4. 登陆成功




> 16. 你知道哪些实现业务解耦的方法？

解耦是一种很重要的软件工程原则，它可以提高代码的质量和可复用性，降低系统的耦合度和维护成本。

解耦在日常开发中很常见，如 AOP 可以将需要切入的逻辑（日志、事务、权限）从核心业务中分离出来、IOC 可以将对象的创建和依赖管理交给容器。

可以通过 `事件驱动` 实现业务之间的解耦，通过事件驱动的实现方式常用的有两种：

1. 基于发布订阅模式的事件驱动

MQ 就是这样实现解耦，这种方式在解耦的同时，还实现了异步，提高了系统的吞吐量和接口响应速度。

成熟的消息队列的功能一般比较成熟，自带消息持久化、负载均衡、消息高可用。

除此之外 Redis 也有发布订阅功能（pub/sub），但是存在消息丢失、消息堆积等问题，不如专业的消息队列。

2. 基于观察者模式的事件驱动

常见的基于观察者模式的事件驱动框架有：Spring Event、Guava EventBus 等

Spring Event 和 Guava EventBus 默认是同步的，但也能实现异步，只是功能比较鸡肋。

观察者模式就只有观察者和被观察者，两者是直接进行交互的。

Spring Event 示例：

```java
// 事件发布者
@Component
public class CustomSpringEventPublisher {
    @Autowired
    private ApplicationEventPublisher applicationEventPublisher;

    public void publishCustomEvent(final String message) {
        System.out.println("Publishing custom event. ");
        CustomSpringEvent customSpringEvent = new CustomSpringEvent(this, message);
        applicationEventPublisher.publishEvent(customSpringEvent);
    }
}

// 事件监听者
@Component
public class CustomSpringEventListener implements ApplicationListener<CustomSpringEvent> {
    @Override
    public void onApplicationEvent(CustomSpringEvent event) {
        System.out.println("Received spring custom event - " + event.getMessage());
    }
}
```



# 项目难点

> 1. 登陆日志原本是同步写入库的，后来为了提升效率，加入了队列，先写队列后消费入库，做解耦，但是队列用了同步操作，有一个 mq 挂了，导致登陆服务不可用，这种事不可以接受的，记录日志不能影响登录，所以将其改为了异步方式


> 2. ​



# 计算机基础

> 1. 堆和树的区别？应用场景？二叉搜索树是什么？


> 2. 进程间的通信方式？死锁条件？怎么解决？


> 3. 操作系统内存满了怎么办？如何回收？有什么影响


> 4. 什么是僵尸进程？应该怎么去操作？


> 5. 为什么会有线程安全的问题，如何解决？


> 6. 乐观锁和悲观锁？CAS？aba问题是什么，如何解决？


> 7. http 常见的方法和状态码有哪些？502是什么错误？如何排查问题？讲一下反向代理？


> 8. token 和 cookie 的区别？

> 9. https 怎么存放密钥？





# Java 基础

> 1. hashcode 和 equals 区别？只重写 equals 行不行？
> 2. Collection 和 List 详细讲一下？
> 3. hash map 和 hash table 的区别？




# Mysql

> 1. 为什么 mysql 删了行记录，反而磁盘空间没有减少？（软删除）

> 2. 数据导入，如何批量导入，这么大的数据量能一次性导入吗？

> 3. 索引构成？（B+树）索引优化？给个 sql 让判断走索引的情况？

> 4. 为什么索引能提高查询速度？

> 5. 聚集索引和非聚集索引的区别？非聚集索引一定回表查询吗？

> 6. 索引这么多有点，为什么不对表中的每一个列创建一个索引呢？使用索引一定提高查询性能吗？

> 7. 索引底层的数据结构了解吗？Hash 索引和 B + 树索引优劣分析

> 8. B+树做索引比红黑树好在哪里？

> 9. 最左前缀匹配原则？

> 10. 什么是覆盖索引？

> 11. 如何查看某条 SQL 语句是否用到了索引？

> 12. 什么是慢 sql，如何查找，如何优化？

> 13. mysql 的三大日志？

> 14. mysql 的事务隔离级别？各自解决了什么问题？mvcc的流程？

> 15. mysql 性能怎么优化？

索引（比如覆盖索引、最左前缀匹配原则）、表结构（选择合适的字段属性和数据类型）、SQL基本编写规范、优化慢SQL（慢SQL定位、Explain 命令使用）、分库分表和读写分离、加强运维（比如通过一些监控工具监控慢 SQL）

可以先聊慢SQL定位以及EXPLAIN 命令的应用，再聊索引、表结构以及SQL基本编写规范，分库分表和读写分离这些最后考虑。如非迫不得已，一定不需要选择分库分表，带来的问题不少

读写分离：https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html

https://javaguide.cn/database/mysql/mysql-high-performance-optimization-specification-recommendations.html


> 16. 索引失效七种？



> 17. mysql 的三大 log 的执行时机？redolog刷盘时机？



> 18. 一条模糊查询语句，查询速度越来越慢怎么排查？

从两个方面进行排查：

1. 确认是否建立了索引
2. 确认索引是否生效

> 19. 在评论时，同时操作多张表如何保证数据的一致性？







# SQL常见面试题

https://javaguide.cn/database/sql/sql-questions-01.html#%E6%A3%80%E7%B4%A2%E9%A1%BE%E5%AE%A2%E5%90%8D%E7%A7%B0%E5%B9%B6%E4%B8%94%E6%8E%92%E5%BA%8F








# 锁

1. 什么是滑块锁?





# 消息队列

1. 除了使用 mq 解耦发奖流程外，有没有别的解决方案？


   答：异步MQ的方案非常成熟，也没有见到其他更合适的方案（如果面试官问了，可以反问他）

   这里mq的用途可以看作是中转分流的任务。中转分流不止MQ可以做，网关也是在中转分流，只不过是没有存储功能。

   无非就是你设计一个能分发任务的路由层，保证任务分发前别丢了，就行。这就是思想，出题人要的是这个。然后再谈具体实现，这又是基本功了。



2. RabbitMQ 的消息可靠性



3. RabbitMQ 的消息幂等性



4. 为什么用 MQ 不用 HTTP？

削峰、解耦、异步







# JVM

> 1. 写代码时候有没有什么方式尽量减少Full GC的概率?

   答：(1)避免一次性加载大量数据加载到内存，比如excel导入导出，jdbc数据库查询
   (2)避免大对象的代码处理业务链流程过长，比如aop中获取到了对象参数，大对象捕获到了，导致对象生命周期变长了，没及时释放。
   (3)禁止使用system.gc方法
   (4)、避免在使用threalocal后，未主动调用remove方法

   尽量避免大对象的使用，以及频繁的创建和销毁。更要避免全局锁的竞争等。



# Redis

> 1. Redisson 分布式锁

> 2. 问了 zset 的底层？为什么不用红黑树？

> 3. redis 里面的命令，比如 setnx 和 setex 还有 zset 中的命令

> 4. redis 的 key 有大小的限制吗？有什么影响？怎么办？

> 5. redis 的内存淘汰策略？

> 6. 根据 score 查 member 的时间复杂度？反过来根据 member 查 score 时间复杂度？

> 7. 线上问题：

   环境 suse + redis4 （3台虚拟机，3主3从）

   分析日志： redis 访问超时偶然发生，大部分超时在应用重试后可正常访问。

   排查结果： 容器与 redis 连接正常、网络设备负载正常、cpu 使用率正常、redis 的 qps 正常、redis 无慢查询

   运维给出结论：redis 连接数过多，性能达到瓶颈

   生产处置：

   - redis 服务重启，为缓解
   - 收集系统日志，低峰期重启 redis 所在虚拟机，现象缓解

   后续排查结果：

   redis 配置文件中 `tcp-backlog` 参数可能会导致该现象。每个 TCP 请求都要经过半连接队列 -> 已完成队列 -> redis 主线程 的排队执行过程，发生问题的机器 `tcp-backlog` 使用默认值时为 511，由于 `redis` 为单线程，出现连接队列满的情况时，后续 tcp 请求将会被丢弃，客户端发生超时。并且 `tcp-backlog` 对应系统层 `net.coire.somaxconn`，该参数虚拟机设置为 2048，将 `tcp-backlog` 改为 2048，该现象消失。

   最终结论：tcp 请求半连接队列打满，导致后续 tcp 请求被丢弃，发生超时

   后续处理：

   - 部署虚拟机监控，监控 overflowed 增长情况
   - redis 设施升级，改为7主7从，redis 升级为 6

> 8. 缓存怎么保证数据的一致性？

> 9. 什么时候做缓存的清理？

   答：设置5~10分钟的过期时间

> 10. zset 几个命令的时间复杂度？ 

> 11. redis 的 key 多大才算是大 key？如何解决？



> 12. 缓存雪崩的解决方案？




# Spring 

1. Spring 循环依赖了解吗，怎么解决？

   参考文章：https://juejin.cn/post/7146458376505917447

   https://mp.weixin.qq.com/s/cqkZEvmmh7jnNt2K5r_lXg

   https://juejin.cn/post/7218080360403615804

   ​

   循环依赖是指 Bean 对象循环引用，是两个或多个 Bean 之间相互持有对方的引用，例如 `A -> B -> A`

   单个对象的自我依赖也会出现循环依赖，但这种概率极低

   - SpringBoot 2.6x 以前是默认允许循环依赖的，即使出现了循环依赖也不会报错。
   - 解决办法：三级缓存机制，提前暴露的对象存放在三级缓存中，二级缓存存放半成品的 bean，一级缓存存放最终的 bean。但是三级缓存也存在一些缺点，比如增加了内存开销，需要维护3个map，降低了性能（需要进行多次检查和转换），并且少部分情况下不支持循环依赖，如非单例的 bean 和 @Async 注解的 bean 无法支持循环依赖

# Spring Boot

> 1. 使用的数据库连接池是什么？
> 2. Spring Boot 默认的数据库连接池是什么？
> 3. Spring Boot 如果需要增加 Redis 功能，需要在 pom 增加什么依赖？
> 4. 鉴权常用的办法？
> 5. Spring Boot 中哪里用到了反射机制？

# Spring Cloud

> 1. Spring Cloud 和 Dubbo 的区别



> 2. Sentinel 熔断机制




> 3. Spring Gateway 网关的作用



# 分布式

> 1. raft 算法选举流程？




# 多线程

项目推荐：京东的 asyncTool 并发框架，大量使用到了 `CompletableFuture`。



1. 如何设计一个能够根据优先级来执行的线程池？

首先对于阻塞队列，可以考虑使用 `PriorityBlockingQueue `作为任务队列。

`PriorityBlockingQueue` 是一个支持优先级的无解阻塞队列，要想对任务进行排序，需要让提交到线程池的任务实现 `Comparable` 接口，并重写 `compareTo` 方法来指定任务之间的优先级比较规则，还有一种方式就是创建 `PriorityBlockingQueue` 时传入一个 Comparator 对象来制定任务之间的排序规则（推荐第二种方式）。

但是还存在几个问题：

1. 在使用优先级任务队列时，当生产者速度快于消费者时，时间长之后会造成 OOM，因为该队列并不会阻塞生产者，只会阻塞消费者，当没有任务消费时，会阻塞消费者
2. 会导致饥饿问题，即优先级低的任务长时间不执行
3. 由于对队列中的元素进行排序以及保证线程安全（并发控制采用的可重入锁 ReentrantLock），因此会降低性能

对于 OOM 问题，可以继承 `PriorityBlockingQueue` 并且重写 `offer` 方法，即入队逻辑，当插入的元素数量超过指定值就返回 false

饥饿问题可以通过优化设计来解决，比如等待时间过长的任务会被移除，并重新添加到队列中，并且提升优先级







# 工作流相关资源（未整理）

总结了一些工作流引擎相关的优质文章和开源项目，分享一下，最近有好几个球友问到。内容较多，建议收藏，后续如果看到比较优质的工作流学习资源会持续同步到这里来。

一些讲解工作流引擎的优质文章：

1. 老板要我开发一个简单的工作流引擎（ [老板要我开发一个简单的工作流引擎 - MCTW - 博客园](https://www.cnblogs.com/duck-and-duck/p/14436373.html) ）：比较有意思的一篇文章，通过过关的形式讲解工作流引擎的开发设计。
2. 一文读懂工作流（ [一文读懂工作流 - 知乎](https://zhuanlan.zhihu.com/p/113387814) ）：网上关于工作流引擎有比较多的简介，也有很多工作流的实际应用场景。本文结合笔者多年对工作流的经验来阐述一下对工作流的理解。
3. 工作流引擎原理-打造一款适合自己的工作流引擎（ [工作流引擎原理-打造一款适合自己的工作流引擎 - 掘金](https://juejin.cn/post/6844904167463485453) ）：作为开发人员或多或少都会接触过工作流引擎，如 activiti、 jbpm 等，这些工作流引擎都会比较重。在小项目中引入就会显得不是很优雅。本文主要简单介绍工作流引擎的原理并讲述如何慢慢打造一款适合自己的工作流引擎。
4. Flowable 开篇，流程引擎扫盲（ [Flowable 开篇，流程引擎扫盲 - 掘金](https://juejin.cn/post/7148248663762927653) ） ：介绍了为什么需要流程引擎，以及开发工作流时用到的一些工具。
5. SpringBoot+Vue+Flowable，模拟一个请假审批流程（ [SpringBoot Vue Flowable，模拟一个请假审批流程！ - 掘金](https://juejin.cn/post/7130150061257785351) ） ：一个很不错的基于 Flowable 的请假审批流程实战。

开源工作流引擎：

1. Flowable ：[Open Source](https://flowable.com/open-source/)
2. Activiti：<https://www.activiti.org/>

开源工作流实战项目：

1. [RuoYi-flowable: 🌟 基于RuoYi-vue    flowable 6.7.2 的工...](https://gitee.com/tony2y/RuoYi-flowable)：基于RuoYi-Vue +Flowable6.x的工作流管理平台。
2. [RuoYi-Flowable-Plus: 本项目基于 RuoYi-Vue-Plus 进行二次开发扩展...](https://gitee.com/KonBAI-Q/ruoyi-flowable-plus)：基于 RuoYi-Vue-Plus 进行二次开发扩展Flowable工作流功能，支持在线表单设计和丰富的工作流程设计能力。

国内用的比较多的还是 Flowable 和 Activiti 这两个，参考资料也蛮多的。Camunda 也不错，更轻量，功能也很完善，性能和稳定性也很不错。关于开源流程引擎的选择，可以参考这篇文章：[开源流程引擎哪个好，如何选型？ - 知乎](https://zhuanlan.zhihu.com/p/369761832) 。

多提一点，国内比较火的工作流引擎 LiteFlow（ [LiteFlow](https://liteflow.cc/) ） 只做基于逻辑的流转，而不做基于角色任务的流转。如果你想做基于角色任务的流转，推荐使用 Flowable 和 Activiti 这两个框架。也就是说，像审批流（A 审批完应该是 B 审批，然后再流转到 C 角色）这种 LiteFlow 就不适合了。LiteFlow 适用于拥有复杂逻辑的业务，比如说价格引擎，下单流程等，这些业务往往都拥有很多步骤，这些步骤完全可以按照业务粒度拆分成一个个独立的组件，进行装配复用变更。